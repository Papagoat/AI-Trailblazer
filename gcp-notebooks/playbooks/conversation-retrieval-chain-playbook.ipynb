{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a7bfae8-a9f0-4985-8fe0-73f3b05f47d4",
   "metadata": {},
   "source": [
    "# Conversation Retrieval Chain\n",
    "\n",
    "This chain takes user input and does the following:\n",
    "\n",
    "    1. Creates a standalone question using\n",
    "        - Few shot examples\n",
    "        - Chat history\n",
    "        - Initial question\n",
    "\n",
    "\n",
    "    2. Provides an answer using\n",
    "        - Standalone question\n",
    "        - Retrieved documents based on the standalone question\n",
    "        - Few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aded577c-0489-4e82-b11c-880abe65e808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-discoveryengine in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.11.7)\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (1.43.0)\n",
      "Requirement already satisfied: langchain-core in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.1.28)\n",
      "Requirement already satisfied: langchain in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.1.10)\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (1.7.4)\n",
      "Requirement already satisfied: langchain-community in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.0.25)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (2.15.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-discoveryengine) (2.25.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-discoveryengine) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-discoveryengine) (4.25.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform) (3.14.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform) (1.11.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain-core) (3.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain-core) (0.1.10)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain-core) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain-core) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (1.62.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-discoveryengine) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from requests<3,>=2->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from requests<3,>=2->langchain-core) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from requests<3,>=2->langchain-core) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "! /opt/conda/envs/python3-11-6/bin/python3.11 -m pip install --no-cache-dir google-cloud-discoveryengine google-cloud-aiplatform langchain-core langchain faiss-cpu langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7bf28ac-2d89-4c18-9895-22213b9a4f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls /opt/conda/envs/python3-11-6/bin | grep python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c70267-c75a-4fcb-a6a5-3ca69e7d27df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d8a2d6-4ecb-4523-9a15-dc83834d18ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff694550-04d4-46e4-b3f1-511a24a3704b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8786bb11-107d-41a8-8440-a9c6e7ae59d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import faiss\n",
    "\n",
    "from operator import itemgetter\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "from langchain.chat_models.vertexai import ChatVertexAI\n",
    "from langchain.vectorstores import MatchingEngine\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, FewShotChatMessagePromptTemplate, ChatMessagePromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, CommaSeparatedListOutputParser\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda, RunnableSequence\n",
    "from langchain.schema import format_document\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompt_values import ChatPromptValue, StringPromptValue\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "PROJECT_ID=\"engaged-domain-403109\"\n",
    "REGION=\"asia-southeast1\"\n",
    "GCS_BUCKET=\"engaged-domain-403109-me-bucket\"\n",
    "ME_INDEX_ID=\"projects/510519063638/locations/asia-southeast1/indexes/4693366538231611392\"\n",
    "ME_ENDPOINT_ID=\"projects/510519063638/locations/asia-southeast1/indexEndpoints/3617586769429528576\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e16692-4a75-47ec-9e55-92a6bc9fd503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_TEMPLATE = \"\"\"You are a helpful assistant from the Singapore government to caregivers or persons with disabilities, including the elderly. You are able to suggest relevant grants and schemes based on their unique circumstances and type of support they are looking for. You are most familiar with financial grants and schemes, but should still be able to answer generic questions related to caregiving or other support for persons with disabilities. \n",
    "You should first understand what type of support they are looking for. Only then, you should proceed to ask them for more information in order to provide more relevant recommendations. If possible, try to anticipate what they need and assess relevant information based on the context they provide. Determine the subject of their responses based on context of the most recent messages they have sent.\n",
    "As part of your assessment to provide recommendations, you should ideally consider the beneficiary's age, impairment, activities of daily living that they need assistance with, and the average income per capita in their household. With regard to the activites of daily living, there are six pre-defined categories you should look out for: eating, dressing, toileting, bathing, walking or moving around, transferring from bed to chair and vice versa. \n",
    "\n",
    "If the user is unwilling to share any information, do not force them to disclose this information, but don't give up. Move on to ask for other details instead. \n",
    "The more details you know, the more relevant suggestions you can give by narrowing them down based on the eligibility criteria. The less details you know, the more generic suggestions you can give. Even if the user provides no details, try to give them at least the most generic suggestions, even if it means giving them some examples of all available solutions.\n",
    "\n",
    "English might not be your user's first language. Always ensure that your responses are concise, easy to read and understand.Ask them questions one at a time as follow-up instead of overwhelming them with multiple questions at once. \n",
    "Your responses should always be empathetic but not sympathetic and respectful to preserve the dignity of the caregiver or persons with disabilities. Always revise your response to replace or explain technical jargons, and match the complexity of language to the human's inputs, without being condescending or using derogatory terms.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "STANDALONE_TEMPLATE = \"\"\"Imagine you are assisting someone who specialises in helping caregivers or persons with disabilities. Your task is to refine a given user question by incorporating relevant context from a given conversation history. Respond with an enhanced standalone question that reflects a deeper understanding of the user's needs. Follow these steps in your response: \n",
    "1. Begin by analysing the given user question related to caregivers or persons with disabilities. Identify key themes and keywords without making any assumptions.\n",
    "2. Consider the provided conversation history to understand the context of the ongoing discussion and any relevant topics or details. Think critically and identify explain your judgement on how relevant the given pieces of the conversation history is to the user's question.\n",
    "3. Integrate only pieces from the conversation history that you have evaluated as relevant as context into the user question without making any assumptions or referring to your own knowledge. If there is no relevant context identified from the conversation history, do not alter the given user question at all, and you should return the same given user question as your refined question. \n",
    "5. Ensure that the refined question is clear, coherent and reflects a deeper understanding of the user's situation on its own, without a need refer to any of the given conversation history. \n",
    "6. Make an overall judgement on how well the refined standalone question incorporates pertinent details from the given conversation history. \n",
    "7. Evaluate if the refined standalone question requires a response with information about specific grants that are either explicitly mentioned in the question, or you identify as relevant examples. \n",
    "8. If no, identify the main subject of each topic and set it as a topic. If yes, identify the name of the grant and set it as the topic.\n",
    "The previous conversation is: \n",
    "{chat_history}\n",
    "\n",
    "\n",
    "Follow Up Input: {question}\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "# Original \n",
    "ANSWER_TEMPLATE = \"\"\"Try to answer the question based on the following context:\n",
    "{context}\n",
    "\n",
    "The examples are:\n",
    "{examples}\n",
    "\n",
    "These examples are only teaching you how to navigate a conversation around a specific topic. You should not replace the current question topic with the example topic.\n",
    "\n",
    "Be precise and concise with your answer. Do not include half-finished sentences.\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# COT implementation\n",
    "# ANSWER_TEMPLATE = \"\"\"Try to answer the question based on the following context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "\n",
    "# Topic: {topic}\n",
    "\n",
    "# Examples: {examples}\n",
    "\n",
    "# Follow these steps in your response:\n",
    "# 1. Understanding the intent of the question.\n",
    "# 2. Use the examples a reference in helping you understanding the nature of the input question.\n",
    "# 3. These examples are only teaching you how to navigate a conversation around a specific topic. You should not replace the topic with the example topic.\n",
    "# 4. In addition, reference the topic when crafting your answer.\n",
    "# 3. Be precise and concise with your answer. Do not include half-finished sentences.\n",
    "\n",
    "# {format_instructions}\n",
    "# \"\"\"\n",
    "\n",
    "# 1. Evaluate if the question requires a response with information about specific grants that are either explicitly mentioned in the question, or you identify as relevant examples. \n",
    "# 2. If no, skip to point 3. If yes, craft a response for each relevant grant you have identified by following these steps: \n",
    "INFO_TEMPLATE = \"\"\"Try to provide a list of summarized points based on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Topic: {topic}\n",
    "\n",
    "Follow these steps in your response:\n",
    "1. Evaluate if the topic is a grant and/or the question requires a response with information about specific grants that are either explicitly mentioned in the question, or you identify as relevant examples. \n",
    "2. If no, skip to point 3. If yes, craft a response for each relevant grant you have identified by following these steps: \n",
    "2a. [Grants] In this case, the topic should be the name of the grant.\n",
    "2b. [Grants] For each of the following sub-topics, first set these sub-topics from 2b - 2f as the title. Then, consider the context and craft a description about it.\n",
    "2c. [Grants] About the grant\n",
    "2d. [Grants] Eligibility\n",
    "2e. [Grants] Expected benefits\n",
    "2f. [Grants] Application process\n",
    "\n",
    "3. Evaluate if the question requires a response with information about a general topics. Craft a response for each relevant topic you have identified by following these steps: \n",
    "3a. Identify the main subject of each topic and set it as a topic. \n",
    "3b. Consider the context, and craft a description about it. Each description should be self-contained, and should not be mentioned in another description point. Where relevant, include examples in this description\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb10548-80d1-4294-81f9-30b54e57507c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Should be the examples to guide the crafting of standalone quesitons\n",
    "FEWSHOT_ANSWER_EXAMPLES = [\n",
    "    {\n",
    "        \"human\": \"My grandma just had an accident and I don't know what to do.\",\n",
    "        \"ai\": \"I'm really sorry to hear about your grandma's accident. I'm here to help. Could you please provide more details about the situation? What happened, and what kind of assistance or information are you looking for? I'll do my best to support you.\"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"What kind of help can I get when my parents are getting old?\",\n",
    "        \"ai\": \"As your parents age, different types of help are available, like support with daily tasks, healthcare, or financial assistance. To give better suggestions, could you share what your parents need and the type of help you're looking for?\"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"What can I do to help my grandfather?\",\n",
    "        \"ai\": \"I'm glad to help you find support for your grandfather. To give you more relevant suggestions, could you please share what kind of support you're looking for? Are you looking for financial assistance, help with daily tasks, or something else?\"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"What kind of support is available to caregivers?\",\n",
    "        \"ai\": \"Caregivers can get different kinds of help. This includes support with daily tasks, finances, and resources for information. To offer more specific suggestions, could you tell me more about your caregiving situation and the type of support you need?\"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"What are ADLs?\",\n",
    "        \"ai\": \"\"\"\"ADLs, or Activities of Daily Living, are everyday tasks we usually do without help. There are 6 ADLs in Singapore:\n",
    "1. Eating\n",
    "2. Bathing\n",
    "3. Dressing\n",
    "4. Using the toilet\n",
    "5. Moving from a bed to chair or chair to bed\n",
    "6. Walking or moving around\n",
    "It's good to know about ADLs because they can affect your eligibility for certain support grants and schemes. If you have more questions or need examples, feel free to ask!\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"Maybe money?\",\n",
    "        \"ai\": \"That's a good start. To provide more relevant recommendations, could you share more details about your situation? For example, what is the average income per capita in the household?\"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"I don't want to share financial details\",\n",
    "        \"ai\": \"That's okay. You don't have to share that information if you're not comfortable. There are still other ways I could help. Could you tell me more about the situation or challenges your grandparents are facing? \"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"They are on a wheelchair\",\n",
    "        \"ai\": \"\"\"\"I noticed that your grandma uses a wheelchair, which may indicate she might need help with daily activities like:\n",
    "- Bathing\n",
    "- Using the toilet\n",
    "- Moving from bed to chair or chair to bed\n",
    "- Walking or moving around\n",
    "Is this information correct? If you can think of any other activities or have any questions, let me know!\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "FEWSHOT_STANDALONE_QUESTION_EXAMPLES = [\n",
    "    {\n",
    "        \"human\": \"What is ADL?\",\n",
    "        \"chat_history\": \"\",\n",
    "        \"ai\": \"What is ADL?\"\n",
    "    },\n",
    "    {\n",
    "        \"human\": \"Name me a few\",\n",
    "        \"chat_history\": \"human:  What is SPED?\\nai: ' SPED stands for Special Education. SPED schools cater to children and youths with special needs who require more intensive and specialised assistance.'\",\n",
    "        \"ai\": \"Name me a few SPED schools in Singapore\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0054014d-3dcf-4b4a-b76a-90b949fdd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "def debug_fn(x):\n",
    "    \"\"\"This function takes a generic, and prints it before passing it on to the next function.\n",
    "\n",
    "    Think of it as a middleware.\n",
    "\n",
    "    Examples: \n",
    "    answer = {\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "            # pylint: disable-next=not-callable\n",
    "            \"answer\": final_inputs | ANSWER_PROMPT | debug_fn | self.model,\n",
    "            \"docs\": itemgetter(\"docs\"),\n",
    "        }\n",
    "\n",
    "    standalone_question = {\n",
    "            \"standalone_question\": {\n",
    "                \"question\": lambda x: x[\"question\"],\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "            }\n",
    "            | CONDENSE_QUESTION_PROMPT\n",
    "            | debug_fn\n",
    "            | self.model\n",
    "            | StrOutputParser(),\n",
    "        }\n",
    "    \"\"\"\n",
    "    if isinstance(x, (ChatPromptValue, StringPromptValue)):\n",
    "        prompt_val = x.to_string()\n",
    "        pp.pprint({\n",
    "          \"len\": len(prompt_val),\n",
    "          \"prompt_val\": prompt_val,\n",
    "        })\n",
    "    else:\n",
    "        # Prints input as is\n",
    "        pp.pprint(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_vector_search_retriever():\n",
    "    \"\"\"\n",
    "    This method returns a retriever using vector search (ie. Matching Engine)\n",
    "    \"\"\"\n",
    "    # PROJECT_ID = 'PROJECT_ID'\n",
    "    # REGION = 'REGION'\n",
    "    # GCS_BUCKET = 'GCS_BUCKET'\n",
    "    # ME_INDEX_ID = 'ME_INDEX_ID'\n",
    "    # ME_ENDPOINT_ID = 'ME_ENDPOINT_ID'\n",
    "\n",
    "    embeddings = VertexAIEmbeddings(location=REGION, model_name=\"textembedding-gecko@001\")\n",
    "\n",
    "    me = MatchingEngine.from_components(\n",
    "        project_id=PROJECT_ID,\n",
    "        region=REGION,\n",
    "        gcs_bucket_name=GCS_BUCKET,\n",
    "        embedding=embeddings,\n",
    "        index_id=ME_INDEX_ID,\n",
    "        endpoint_id=ME_ENDPOINT_ID,\n",
    "    )\n",
    "\n",
    "    NUMBER_OF_RESULTS = 4\n",
    "\n",
    "    # Expose index to the retriever\n",
    "    # https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.matching_engine.MatchingEngine.html?highlight=matchingengine#langchain_community.vectorstores.matching_engine.MatchingEngine.as_retriever\n",
    "    retriever = me.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": NUMBER_OF_RESULTS,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return retriever\n",
    "\n",
    "def get_memory_retriever():\n",
    "    \"\"\"\n",
    "    This method returns a vector store retriever that retrieves stored memories\n",
    "    \"\"\"\n",
    "    EMBEDDING_SIZE = 768\n",
    "    index = faiss.IndexFlatL2(EMBEDDING_SIZE)\n",
    "    embedding_fn = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")\n",
    "\n",
    "    # pylint: disable-next=not-callable\n",
    "    vectorstore_memory = FAISS(embedding_fn, index, InMemoryDocstore({}), {})\n",
    "\n",
    "    retriever = vectorstore_memory.as_retriever(search_kwargs={\"k\": 2})\n",
    "    memory = VectorStoreRetrieverMemory(\n",
    "        retriever=retriever,\n",
    "        return_messages=True,\n",
    "        input_key=\"human\",\n",
    "        output_key=\"ai\"\n",
    "    )\n",
    "\n",
    "    return memory\n",
    "\n",
    "def get_fewshot_example_selector(examples, k=2):\n",
    "    \"\"\"\n",
    "    This method returns an example selector that select from a series of \n",
    "    examples to dynamically place in-context information into your prompt.\n",
    "    \"\"\"\n",
    "    embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")\n",
    "    return SemanticSimilarityExampleSelector.from_examples(\n",
    "        examples,\n",
    "        embeddings,\n",
    "        FAISS,\n",
    "        k\n",
    "    )\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    \"\"\"This method formats documents into a string\"\"\"\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468bf1e6-292b-4774-956a-c7d210136663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chat_models.vertexai import ChatVertexAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, FewShotChatMessagePromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser, JsonOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableSequence\n",
    "\n",
    "\n",
    "class StandaloneQuestionOutput(BaseModel):\n",
    "    \"\"\"Typings for standalone question output item\"\"\"\n",
    "    topic: str = Field(\n",
    "        description=\"This the main topic of the refined standalone question.\")\n",
    "    standalone_question: str = Field(\n",
    "        description=\"This is the refined standalone question.\")\n",
    "\n",
    "class InfoItem(BaseModel):\n",
    "    \"\"\"Typings for description item\"\"\"\n",
    "    content: str = Field(\n",
    "        description=\"This is the content string for each description item.\")\n",
    "    title: str = Field(\n",
    "        description=\"This is the title associated with each description item. It summarizes the content string.\")\n",
    "\n",
    "\n",
    "class InfoOutput(BaseModel):\n",
    "    \"\"\"Typings for descriptions chain output\"\"\"\n",
    "    details: List[InfoItem] = Field(\n",
    "        description=\"This is the list of InfoItems.\")\n",
    "    explanation: str = Field(\n",
    "        description=\"This is the explanation of your thought process in crafting the entire output. Be as thorough and detailed as you can be.\")\n",
    "\n",
    "\n",
    "class ConversationalRetrievalChain():\n",
    "    \"\"\"\n",
    "    This class creates a chain that attempts to FIRST answer user question on the dataset before falling back on its own knowledge.\n",
    "\n",
    "    final_chain = loaded_memory | standalone_question | retrieved_documents | answer / descriptions | updateMemory    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"This method instantiates an instance of ConversationalRetrievalChain\"\"\"\n",
    "        # https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models\n",
    "        # pylint: disable-next=not-callable\n",
    "        self.model = ChatVertexAI(\n",
    "            model_name=\"chat-bison-32k\", temperature=0, max_output_tokens=8192)\n",
    "        self.memory = get_memory_retriever()\n",
    "        self.retriever = get_vector_search_retriever()\n",
    "        self.chain = self.get_chain()\n",
    "\n",
    "    def get_chain(self) -> RunnableSequence:\n",
    "        \"\"\"This method instantiates the chain\"\"\"\n",
    "        loaded_memory = RunnableParallel({\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "            \"chat_history\": lambda x: self.memory.load_memory_variables({\"human\": x[\"question\"]})[\"history\"]\n",
    "        })\n",
    "\n",
    "        retrieved_documents = RunnablePassthrough.assign(\n",
    "            docs=itemgetter(\"standalone_question\") | self.retriever\n",
    "        )\n",
    "\n",
    "        # get chains\n",
    "        standalone_question_chain = self.get_standalone_question_chain()\n",
    "        answer_chain = self.get_answer_chain()\n",
    "        info_chain = self.get_info_chain()\n",
    "\n",
    "        update_memory = RunnablePassthrough.assign(\n",
    "            _=lambda x: self.save_to_memory(x[\"question\"], x[\"answer\"]),\n",
    "        )\n",
    "\n",
    "        final_chain = (\n",
    "            loaded_memory\n",
    "            | standalone_question_chain\n",
    "            | retrieved_documents\n",
    "            | RunnableParallel({\n",
    "                \"question\": lambda x: x[\"standalone_question\"],\n",
    "                \"topic\": lambda x: x[\"topic\"],\n",
    "                \"answer\": answer_chain,\n",
    "                \"information\": info_chain\n",
    "            })\n",
    "            | update_memory\n",
    "        )\n",
    "\n",
    "        return final_chain\n",
    "\n",
    "    def save_to_memory(self, question: str, answer: str) -> None:\n",
    "        \"\"\"This method saves chat history to memory\"\"\"\n",
    "        self.memory.save_context({\"human\": question}, {\"ai\": answer})\n",
    "\n",
    "    def get_standalone_question_chain(self) -> RunnableSequence:\n",
    "        \"\"\"This method returns the standalone question chain\"\"\"\n",
    "        standalone_question_parser = JsonOutputParser(\n",
    "            pydantic_object=StandaloneQuestionOutput)\n",
    "        CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\n",
    "            STANDALONE_TEMPLATE, partial_variables={\"format_instructions\": standalone_question_parser.get_format_instructions()})\n",
    "\n",
    "        standalone_question_chain = (RunnablePassthrough()\n",
    "                                     | CONDENSE_QUESTION_PROMPT\n",
    "                                     | self.model\n",
    "                                     | standalone_question_parser\n",
    "                                     )\n",
    "\n",
    "        return standalone_question_chain\n",
    "\n",
    "    def get_answer_chain(self) -> RunnableSequence:\n",
    "        \"\"\"This method returns the answer chain\"\"\"\n",
    "        ANSWER_PROMPT = ChatPromptTemplate(messages=[\n",
    "            SystemMessagePromptTemplate.from_template(SYSTEM_TEMPLATE),\n",
    "            HumanMessagePromptTemplate.from_template(ANSWER_TEMPLATE)\n",
    "        ])\n",
    "\n",
    "        FEWSHOT_ANSWER_EXAMPLE_PROMPT = ChatPromptTemplate.from_messages([\n",
    "            (\"human\", \"{human}\"), (\"ai\", \"{ai}\")\n",
    "        ])\n",
    "\n",
    "        FEWSHOT_ANSWER_PROMPT = FewShotChatMessagePromptTemplate(\n",
    "            example_prompt=FEWSHOT_ANSWER_EXAMPLE_PROMPT,\n",
    "            example_selector=get_fewshot_example_selector(\n",
    "                FEWSHOT_ANSWER_EXAMPLES, k=2)\n",
    "        )\n",
    "\n",
    "        final_inputs = {\n",
    "            \"context\": lambda x: combine_documents(x[\"docs\"]),\n",
    "            \"topic\": itemgetter('topic'),\n",
    "            \"question\": itemgetter(\"standalone_question\"),\n",
    "            \"examples\": lambda x: FEWSHOT_ANSWER_PROMPT.format(human=x[\"standalone_question\"]),\n",
    "        }\n",
    "\n",
    "        # answer_chain = final_inputs | ANSWER_PROMPT | self.model | answer_parser | debug_fn\n",
    "        answer_chain = final_inputs | ANSWER_PROMPT | self.model | StrOutputParser()\n",
    "\n",
    "        return answer_chain\n",
    "\n",
    "    def get_info_chain(self) -> RunnableSequence:\n",
    "        \"\"\"This method returns the information chain\"\"\"\n",
    "\n",
    "        # info_parser = CommaSeparatedListOutputParser()\n",
    "        info_parser = JsonOutputParser(pydantic_object=InfoOutput)\n",
    "        INFO_PROMPT = PromptTemplate.from_template(INFO_TEMPLATE, partial_variables={\n",
    "            \"format_instructions\": info_parser.get_format_instructions()\n",
    "        })\n",
    "\n",
    "        info_chain = (\n",
    "            {\n",
    "                \"context\": lambda x: combine_documents(x[\"docs\"]),\n",
    "                \"topic\": itemgetter(\"topic\"),\n",
    "                \"question\": itemgetter(\"standalone_question\")\n",
    "            }\n",
    "            | INFO_PROMPT\n",
    "            | ChatVertexAI(model_name=\"chat-bison-32k\", temperature=0, max_output_tokens=8192)\n",
    "            | info_parser\n",
    "        )\n",
    "\n",
    "        return info_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb3acc6a-9601-4b45-b756-00d75c254dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3-11-6/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.vertexai.ChatVertexAI` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import ChatVertexAI`.\n",
      "  warn_deprecated(\n",
      "/opt/conda/envs/python3-11-6/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.vertexai.VertexAIEmbeddings` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "cr = ConversationalRetrievalChain()\n",
    "cr_chain = cr.chain\n",
    "memory = cr.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a599b9b-2bb7-4cd5-87f7-3211ea9ed124",
   "metadata": {},
   "source": [
    "# Ask your question\n",
    "\n",
    "The chain will answer the question based on whether it can __first__ find relevant documents from the vector store __before__ answering based on its own knowledge.\n",
    "\n",
    "I suggest to perform your prompt engineering in the following sequence: \n",
    "\n",
    "1. `final_chain.invoke({ \"question\" : \"<<YOUR QUESTION>>\" })` -- Ask away\n",
    "2. `memory.load_memory_variables({})`                         -- Check to see if the previous conversation has been saved\n",
    "3. `repeat step 1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e4f4210-11ac-46a4-9259-b0868ae3cf98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3-11-6/lib/python3.11/site-packages/pydantic/v1/main.py:998: RuntimeWarning: fields may not start with an underscore, ignoring \"_\"\n",
      "  warnings.warn(f'fields may not start with an underscore, ignoring \"{f_name}\"', RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= answer ========\n",
      "{ '_': None,\n",
      "  'answer': ' The Home Caregiving Grant (HCG) provides financial assistance to '\n",
      "            \"caregivers of persons with disabilities or the elderly. Here's \"\n",
      "            'more information:\\n'\n",
      "            '\\n'\n",
      "            '**Eligibility:**\\n'\n",
      "            '- Caregivers must be Singapore Citizens or Permanent Residents.\\n'\n",
      "            '- Care recipients must be Singapore Citizens or Permanent '\n",
      "            'Residents with disabilities or aged 60 and above.\\n'\n",
      "            '- Household monthly income per person must be $1,200 or less (or '\n",
      "            'Annual Value of Residence ≤ $13,000 for households without '\n",
      "            'income).\\n'\n",
      "            '\\n'\n",
      "            '**Application Process:**\\n'\n",
      "            '- Applications can be made online via the AIC website or in '\n",
      "            'person at any AIC Link branch.\\n'\n",
      "            '- Required documents include:\\n'\n",
      "            '  - NRIC of caregiver and care recipient\\n'\n",
      "            '  - Proof of income\\n'\n",
      "            \"  - Care recipient's medical report or disability assessment \"\n",
      "            'report\\n'\n",
      "            '\\n'\n",
      "            '**Recent Updates:**\\n'\n",
      "            '- As of March 1, 2023, the HCG payouts have been enhanced from '\n",
      "            '$200 per month to $400 per month for eligible caregivers.\\n'\n",
      "            '\\n'\n",
      "            'For more information, please visit the AIC website or contact the '\n",
      "            'AIC hotline at 1800-650-6060.',\n",
      "  'information': { 'details': [ { 'content': 'The Home Caregiving Grant (HCG) '\n",
      "                                             'was enhanced on March 1, 2023, '\n",
      "                                             'with increased monthly payouts '\n",
      "                                             'to support caregivers and reduce '\n",
      "                                             'caregiving costs, particularly '\n",
      "                                             'for lower-income households.',\n",
      "                                  'title': 'Home Caregiving Grant (HCG)'},\n",
      "                                { 'content': 'To be eligible for the enhanced '\n",
      "                                             'HCG payout of up to $400 per '\n",
      "                                             'month, the household monthly '\n",
      "                                             'income per person must be $0 - '\n",
      "                                             '$1,200, or the Annual Value of '\n",
      "                                             'Residence must be ≤ $13,000 for '\n",
      "                                             'households without income.',\n",
      "                                  'title': 'Eligibility'},\n",
      "                                { 'content': 'The enhanced HCG provides '\n",
      "                                             'additional financial support to '\n",
      "                                             'caregivers, recognizing their '\n",
      "                                             'contributions and helping to '\n",
      "                                             'reduce caregiving costs.',\n",
      "                                  'title': 'Expected benefits'},\n",
      "                                { 'content': 'Information about the '\n",
      "                                             'application process for the HCG '\n",
      "                                             'can be found on the relevant '\n",
      "                                             'government websites, such as the '\n",
      "                                             'Agency for Integrated Care (AIC) '\n",
      "                                             'website.',\n",
      "                                  'title': 'Application process'},\n",
      "                                { 'content': 'The Caregivers Training Grant '\n",
      "                                             '(CTG) offers financial support '\n",
      "                                             'for caregivers to enhance their '\n",
      "                                             'skills and knowledge in '\n",
      "                                             'providing holistic care to their '\n",
      "                                             'loved ones. It covers a range of '\n",
      "                                             'courses, including managing '\n",
      "                                             'day-to-day care, caring for '\n",
      "                                             'individuals with dementia, '\n",
      "                                             'clinical skills, and '\n",
      "                                             'communication and self-care '\n",
      "                                             'skills.',\n",
      "                                  'title': 'Caregivers Training Grant (CTG)'},\n",
      "                                { 'content': 'To be eligible for the CTG, '\n",
      "                                             'individuals must be Singapore '\n",
      "                                             'Citizens or Permanent Residents, '\n",
      "                                             'and they must be the primary '\n",
      "                                             'caregivers of persons with '\n",
      "                                             'disabilities, including '\n",
      "                                             'intellectual disabilities or '\n",
      "                                             'autism spectrum disorder.',\n",
      "                                  'title': 'Eligibility for CTG'},\n",
      "                                { 'content': 'Information about the '\n",
      "                                             'application process for the CTG '\n",
      "                                             'can be found on the relevant '\n",
      "                                             'government websites, such as the '\n",
      "                                             'Ministry of Social and Family '\n",
      "                                             'Development (MSF) website.',\n",
      "                                  'title': 'Application process for CTG'},\n",
      "                                { 'content': 'The Migrant Domestic Worker '\n",
      "                                             '(MDW) Levy Concession provides '\n",
      "                                             'financial assistance to '\n",
      "                                             'employers of migrant domestic '\n",
      "                                             'workers. It offers a monthly '\n",
      "                                             'levy rebate of $120 for '\n",
      "                                             'employers who meet certain '\n",
      "                                             'eligibility criteria, such as '\n",
      "                                             'having a household income per '\n",
      "                                             'person of $1,900 or less.',\n",
      "                                  'title': 'Migrant Domestic Worker (MDW) Levy '\n",
      "                                           'Concession'},\n",
      "                                { 'content': 'To be eligible for the MDW Levy '\n",
      "                                             'Concession, employers must be '\n",
      "                                             'Singapore Citizens or Permanent '\n",
      "                                             'Residents, and they must employ '\n",
      "                                             'a migrant domestic worker to '\n",
      "                                             'provide caregiving services for '\n",
      "                                             'a person with a disability or a '\n",
      "                                             'person aged 65 and above.',\n",
      "                                  'title': 'Eligibility for MDW Levy '\n",
      "                                           'Concession'},\n",
      "                                { 'content': 'Information about the '\n",
      "                                             'application process for the MDW '\n",
      "                                             'Levy Concession can be found on '\n",
      "                                             'the relevant government '\n",
      "                                             'websites, such as the AIC '\n",
      "                                             'website.',\n",
      "                                  'title': 'Application process for MDW Levy '\n",
      "                                           'Concession'}],\n",
      "                   'explanation': 'I have extracted and summarized the key '\n",
      "                                  'information about the Home Caregiving Grant '\n",
      "                                  '(HCG), Caregivers Training Grant (CTG), and '\n",
      "                                  'Migrant Domestic Worker (MDW) Levy '\n",
      "                                  'Concession based on the provided context. '\n",
      "                                  'For each program, I have included details '\n",
      "                                  'about the grant, eligibility criteria, '\n",
      "                                  'expected benefits, and application process, '\n",
      "                                  'where applicable.'},\n",
      "  'question': 'Can you provide more information about the Home Caregiving '\n",
      "              'Grant (HCG), including eligibility criteria, application '\n",
      "              'process, and any recent updates or changes to the program?',\n",
      "  'topic': 'Home Caregiving Grant (HCG)'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about Home Caregiving Grant (HCG).\"\n",
    "\n",
    "result = cr_chain.invoke({ \"question\": question })\n",
    "\n",
    "print(\"======= answer ========\", end=\"\\n\")\n",
    "pp.pprint(result)\n",
    "\n",
    "# print(\"======= docs ========\", end=\"\\n\")\n",
    "# for i,doc in enumerate(result[\"docs\"]):\n",
    "#     pp.pprint(f\"{i}: {doc}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3-11-6",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "python3-11-6 (Local)",
   "language": "python",
   "name": "python3-11-6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
