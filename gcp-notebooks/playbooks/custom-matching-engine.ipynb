{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61146da5-393f-4446-82cd-b3bc256090f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-discoveryengine in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.11.7)\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.35.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (1.35.0)\n",
      "Requirement already satisfied: langchain==0.0.332 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.0.332)\n",
      "Requirement already satisfied: langchain-core in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.1.23)\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (1.7.4)\n",
      "Requirement already satisfied: langchain-community in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.0.20)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (3.8.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (2.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform==1.35.0) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform==1.35.0) (4.25.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform==1.35.0) (23.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform==1.35.0) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform==1.35.0) (3.14.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform==1.35.0) (1.11.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-aiplatform==1.35.0) (2.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (3.9.1)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from langchain==0.0.332) (8.2.3)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-discoveryengine) (2.25.2)\n",
      "Requirement already satisfied: torch==2.2.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.3.101)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.332) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.332) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.332) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.332) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.332) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from anyio<4.0->langchain==0.0.332) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from anyio<4.0->langchain==0.0.332) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.332) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.332) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.62.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.35.0) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.35.0) (2.7.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.35.0) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.35.0) (1.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.332) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.0.332) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.0.332) (2.14.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.332) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.332) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.0.332) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.332) (3.0.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.5.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.332) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/python3-11-6/lib/python3.11/site-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "! /opt/conda/envs/python3-11-6/bin/python3.11 -m pip install --no-cache-dir google-cloud-discoveryengine google-cloud-aiplatform==1.35.0 langchain==0.0.332 langchain-core langchain faiss-cpu langchain-community torchvision tqdm pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "913412c3-e08d-4192-8c43-d90bfe21ed02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth as google_auth\n",
    "\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04fc9c1a-b09f-4c25-9276-70a24b13210e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import time\n",
    "import uuid\n",
    "from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Tuple, Type\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "\n",
    "from langchain_community.utilities.vertexai import get_client_info\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import MatchingEngineIndex, MatchingEngineIndexEndpoint\n",
    "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import (\n",
    "    Namespace,\n",
    ")\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "from langchain_community.embeddings import TensorflowHubEmbeddings\n",
    "\n",
    "from langchain.chat_models.vertexai import ChatVertexAI\n",
    "from langchain.vectorstores import MatchingEngine\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, FewShotChatMessagePromptTemplate, ChatMessagePromptTemplate\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.schema import format_document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List\n",
    "# from pydantic import BaseModel\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5105ef7-17bf-4e0f-a175-0a033ff8658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load adapter matrix\n",
    "with open('data/embedding_adapter_training/adapter_matrix.pickle', 'rb') as f:\n",
    "    best_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b65bc5a-5e7a-493a-886e-66a3cddafe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CustomMatchingEngine(VectorStore):\n",
    "    \"\"\"`Google Vertex AI Vector Search` (previously Matching Engine) vector store.\n",
    "\n",
    "    While the embeddings are stored in the Matching Engine, the embedded\n",
    "    documents will be stored in GCS.\n",
    "\n",
    "    An existing Index and corresponding Endpoint are preconditions for\n",
    "    using this module.\n",
    "\n",
    "    See usage in docs/integrations/vectorstores/google_vertex_ai_vector_search.ipynb\n",
    "\n",
    "    Note that this implementation is mostly meant for reading if you are\n",
    "    planning to do a real time implementation. While reading is a real time\n",
    "    operation, updating the index takes close to one hour.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project_id: str,\n",
    "        index: MatchingEngineIndex,\n",
    "        endpoint: MatchingEngineIndexEndpoint,\n",
    "        embedding: Embeddings,\n",
    "        adapted_embedding: Embeddings,\n",
    "        gcs_client: storage.Client,\n",
    "        gcs_bucket_name: str,\n",
    "        credentials: Optional[Credentials] = None,\n",
    "        *,\n",
    "        document_id_key: Optional[str] = None,\n",
    "    ):\n",
    "        \"\"\"Google Vertex AI Vector Search (previously Matching Engine)\n",
    "         implementation of the vector store.\n",
    "\n",
    "        While the embeddings are stored in the Matching Engine, the embedded\n",
    "        documents will be stored in GCS.\n",
    "\n",
    "        An existing Index and corresponding Endpoint are preconditions for\n",
    "        using this module.\n",
    "\n",
    "        See usage in\n",
    "        docs/integrations/vectorstores/google_vertex_ai_vector_search.ipynb.\n",
    "\n",
    "        Note that this implementation is mostly meant for reading if you are\n",
    "        planning to do a real time implementation. While reading is a real time\n",
    "        operation, updating the index takes close to one hour.\n",
    "\n",
    "        Attributes:\n",
    "            project_id: The GCS project id.\n",
    "            index: The created index class. See\n",
    "                ~:func:`MatchingEngine.from_components`.\n",
    "            endpoint: The created endpoint class. See\n",
    "                ~:func:`MatchingEngine.from_components`.\n",
    "            embedding: A :class:`Embeddings` that will be used for\n",
    "                embedding the text sent. If none is sent, then the\n",
    "                multilingual Tensorflow Universal Sentence Encoder will be used.\n",
    "            gcs_client: The GCS client.\n",
    "            gcs_bucket_name: The GCS bucket name.\n",
    "            credentials (Optional): Created GCP credentials.\n",
    "            document_id_key (Optional): Key for storing document ID in document\n",
    "                metadata. If None, document ID will not be returned in document\n",
    "                metadata.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._validate_google_libraries_installation()\n",
    "\n",
    "        self.project_id = project_id\n",
    "        self.index = index\n",
    "        self.endpoint = endpoint\n",
    "        self.embedding = embedding\n",
    "        self.adapted_embedding = adapted_embedding\n",
    "        self.gcs_client = gcs_client\n",
    "        self.credentials = credentials\n",
    "        self.gcs_bucket_name = gcs_bucket_name\n",
    "        self.document_id_key = document_id_key\n",
    "\n",
    "    @property\n",
    "    def embeddings(self) -> Embeddings:\n",
    "        return self.embedding\n",
    "\n",
    "    def _validate_google_libraries_installation(self) -> None:\n",
    "        \"\"\"Validates that Google libraries that are needed are installed.\"\"\"\n",
    "        try:\n",
    "            from google.cloud import aiplatform, storage  # noqa: F401\n",
    "            from google.oauth2 import service_account  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"You must run `pip install --upgrade \"\n",
    "                \"google-cloud-aiplatform google-cloud-storage`\"\n",
    "                \"to use the MatchingEngine Vectorstore.\"\n",
    "            )\n",
    "    def similarity_search_with_score(\n",
    "        self,\n",
    "        query: str,\n",
    "        k: int = 4,\n",
    "        filter: Optional[List[Namespace]] = None,\n",
    "    ) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"Return docs most similar to query and their cosine distance from the query.\n",
    "\n",
    "        Args:\n",
    "            query: String query look up documents similar to.\n",
    "            k: Number of Documents to return. Defaults to 4.\n",
    "            filter: Optional. A list of Namespaces for filtering\n",
    "                the matching results.\n",
    "                For example:\n",
    "                [Namespace(\"color\", [\"red\"], []), Namespace(\"shape\", [], [\"squared\"])]\n",
    "                will match datapoints that satisfy \"red color\" but not include\n",
    "                datapoints with \"squared shape\". Please refer to\n",
    "                https://cloud.google.com/vertex-ai/docs/matching-engine/filtering#json\n",
    "                for more detail.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[Document, float]]: List of documents most similar to\n",
    "            the query text and cosine distance in float for each.\n",
    "            Lower score represents more similarity.\n",
    "        \"\"\"\n",
    "        logger.debug(f\"Embedding query {query}.\")\n",
    "        embedding_query = self.adapted_embedding.embed_query(query)\n",
    "        return self.similarity_search_by_vector_with_score(\n",
    "            embedding_query, k=k, filter=filter\n",
    "        )\n",
    "\n",
    "    def similarity_search_by_vector_with_score(\n",
    "        self,\n",
    "        embedding: List[float],\n",
    "        k: int = 4,\n",
    "        filter: Optional[List[Namespace]] = None,\n",
    "    ) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"Return docs most similar to the embedding and their cosine distance.\n",
    "\n",
    "        Args:\n",
    "            embedding: Embedding to look up documents similar to.\n",
    "            k: Number of Documents to return. Defaults to 4.\n",
    "            filter: Optional. A list of Namespaces for filtering\n",
    "                the matching results.\n",
    "                For example:\n",
    "                [Namespace(\"color\", [\"red\"], []), Namespace(\"shape\", [], [\"squared\"])]\n",
    "                will match datapoints that satisfy \"red color\" but not include\n",
    "                datapoints with \"squared shape\". Please refer to\n",
    "                https://cloud.google.com/vertex-ai/docs/matching-engine/filtering#json\n",
    "                for more detail.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[Document, float]]: List of documents most similar to\n",
    "            the query text and cosine distance in float for each.\n",
    "            Lower score represents more similarity.\n",
    "\n",
    "        \"\"\"\n",
    "        filter = filter or []\n",
    "\n",
    "        # If the endpoint is public we use the find_neighbors function.\n",
    "        if hasattr(self.endpoint, \"_public_match_client\") and (\n",
    "            self.endpoint._public_match_client\n",
    "        ):\n",
    "            response = self.endpoint.find_neighbors(\n",
    "                deployed_index_id=self._get_index_id(),\n",
    "                queries=[embedding],\n",
    "                num_neighbors=k,\n",
    "                filter=filter,\n",
    "            )\n",
    "        else:\n",
    "            response = self.endpoint.match(\n",
    "                deployed_index_id=self._get_index_id(),\n",
    "                queries=[embedding],\n",
    "                num_neighbors=k,\n",
    "                filter=filter,\n",
    "            )\n",
    "\n",
    "        # NOTE: Rerun document retrieval if documents collected is less than k \n",
    "        #       (due to current vector store having invalid document for a particular index)\n",
    "        for result in response[0]:\n",
    "            if result.id == '025dfeb0-0468-489c-9008-f0a5ed1d24ad':\n",
    "                if hasattr(self.endpoint, \"_public_match_client\") and (\n",
    "                    self.endpoint._public_match_client\n",
    "                ):\n",
    "                    response = self.endpoint.find_neighbors(\n",
    "                        deployed_index_id=self._get_index_id(),\n",
    "                        queries=[embedding],\n",
    "                        num_neighbors=k+1,\n",
    "                        filter=filter,\n",
    "                    )\n",
    "                else:\n",
    "                    response = self.endpoint.match(\n",
    "                        deployed_index_id=self._get_index_id(),\n",
    "                        queries=[embedding],\n",
    "                        num_neighbors=k+1,\n",
    "                        filter=filter,\n",
    "                    )\n",
    "                break\n",
    "                \n",
    "        logger.debug(f\"Found {len(response)} matches.\")\n",
    "\n",
    "        if len(response) == 0:\n",
    "            return []\n",
    "\n",
    "        docs: List[Tuple[Document, float]] = []\n",
    "        \n",
    "        # I'm only getting the first one because queries receives an array\n",
    "        # and the similarity_search method only receives one query. This\n",
    "        # means that the match method will always return an array with only\n",
    "        # one element.\n",
    "        for result in response[0]:\n",
    "            try:\n",
    "                page_content = self._download_from_gcs(f\"documents/{result.id}\")\n",
    "                # TODO: return all metadata.\n",
    "                metadata = {}\n",
    "                if self.document_id_key is not None:\n",
    "                    metadata[self.document_id_key] = result.id\n",
    "                document = Document(\n",
    "                    page_content=page_content,\n",
    "                    metadata=metadata,\n",
    "                )\n",
    "                docs.append((document, result.distance))\n",
    "            except Exception as e:\n",
    "                # print(e)\n",
    "                continue\n",
    "\n",
    "        logger.debug(\"Downloaded documents for query.\")\n",
    "\n",
    "        return docs\n",
    "\n",
    "    def _get_index_id(self) -> str:\n",
    "        \"\"\"Gets the correct index id for the endpoint.\n",
    "\n",
    "        Returns:\n",
    "            The index id if found (which should be found) or throws\n",
    "            ValueError otherwise.\n",
    "        \"\"\"\n",
    "        for index in self.endpoint.deployed_indexes:\n",
    "            if index.index == self.index.resource_name:\n",
    "                return index.id\n",
    "\n",
    "        raise ValueError(\n",
    "            f\"No index with id {self.index.resource_name} \"\n",
    "            f\"deployed on endpoint \"\n",
    "            f\"{self.endpoint.display_name}.\"\n",
    "        )\n",
    "\n",
    "    def _download_from_gcs(self, gcs_location: str) -> str:\n",
    "        \"\"\"Downloads from GCS in text format.\n",
    "\n",
    "        Args:\n",
    "            gcs_location: The location where the file is located.\n",
    "\n",
    "        Returns:\n",
    "            The string contents of the file.\n",
    "        \"\"\"\n",
    "        bucket = self.gcs_client.get_bucket(self.gcs_bucket_name)\n",
    "        blob = bucket.blob(gcs_location)\n",
    "        return blob.download_as_string()\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(\n",
    "        cls: Type[\"MatchingEngine\"],\n",
    "        texts: List[str],\n",
    "        embedding: Embeddings,\n",
    "        metadatas: Optional[List[dict]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"MatchingEngine\":\n",
    "        \"\"\"Use from components instead.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"This method is not implemented. Instead, you should initialize the class\"\n",
    "            \" with `MatchingEngine.from_components(...)` and then call \"\n",
    "            \"`add_texts`\"\n",
    "        )\n",
    "    def add_texts(\n",
    "        self,\n",
    "        texts: Iterable[str],\n",
    "        metadatas: Optional[List[dict]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
    "\n",
    "        Args:\n",
    "            texts: Iterable of strings to add to the vectorstore.\n",
    "            metadatas: Optional list of metadatas associated with the texts.\n",
    "            kwargs: vectorstore specific parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of ids from adding the texts into the vectorstore.\n",
    "        \"\"\"\n",
    "        texts = list(texts)\n",
    "        if metadatas is not None and len(texts) != len(metadatas):\n",
    "            raise ValueError(\n",
    "                \"texts and metadatas do not have the same length. Received \"\n",
    "                f\"{len(texts)} texts and {len(metadatas)} metadatas.\"\n",
    "            )\n",
    "        logger.debug(\"Embedding documents.\")\n",
    "        embeddings = self.embedding.embed_documents(texts)\n",
    "        jsons = []\n",
    "        ids = []\n",
    "        # Could be improved with async.\n",
    "        for idx, (embedding, text) in enumerate(zip(embeddings, texts)):\n",
    "            id = str(uuid.uuid4())\n",
    "            ids.append(id)\n",
    "            json_: dict = {\"id\": id, \"embedding\": embedding}\n",
    "            if metadatas is not None:\n",
    "                json_[\"metadata\"] = metadatas[idx]\n",
    "            jsons.append(json_)\n",
    "            self._upload_to_gcs(text, f\"documents/{id}\")\n",
    "\n",
    "        logger.debug(f\"Uploaded {len(ids)} documents to GCS.\")\n",
    "\n",
    "        # Creating json lines from the embedded documents.\n",
    "        result_str = \"\\n\".join([json.dumps(x) for x in jsons])\n",
    "\n",
    "        filename_prefix = f\"indexes/{uuid.uuid4()}\"\n",
    "        filename = f\"{filename_prefix}/{time.time()}.json\"\n",
    "        self._upload_to_gcs(result_str, filename)\n",
    "        logger.debug(\n",
    "            f\"Uploaded updated json with embeddings to \"\n",
    "            f\"{self.gcs_bucket_name}/{filename}.\"\n",
    "        )\n",
    "\n",
    "        self.index = self.index.update_embeddings(\n",
    "            contents_delta_uri=f\"gs://{self.gcs_bucket_name}/{filename_prefix}/\"\n",
    "        )\n",
    "\n",
    "        logger.debug(\"Updated index with new configuration.\")\n",
    "\n",
    "        return ids\n",
    "    \n",
    "    def similarity_search(\n",
    "        self,\n",
    "        query: str,\n",
    "        k: int = 4,\n",
    "        filter: Optional[List[Namespace]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Return docs most similar to query.\n",
    "\n",
    "        Args:\n",
    "            query: The string that will be used to search for similar documents.\n",
    "            k: The amount of neighbors that will be retrieved.\n",
    "            filter: Optional. A list of Namespaces for filtering the matching results.\n",
    "                For example:\n",
    "                [Namespace(\"color\", [\"red\"], []), Namespace(\"shape\", [], [\"squared\"])]\n",
    "                will match datapoints that satisfy \"red color\" but not include\n",
    "                datapoints with \"squared shape\". Please refer to\n",
    "                https://cloud.google.com/vertex-ai/docs/matching-engine/filtering#json\n",
    "                 for more detail.\n",
    "\n",
    "        Returns:\n",
    "            A list of k matching documents.\n",
    "        \"\"\"\n",
    "        docs_and_scores = self.similarity_search_with_score(\n",
    "            query, k=k, filter=filter, **kwargs\n",
    "        )\n",
    "\n",
    "        return [doc for doc, _ in docs_and_scores]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_components(\n",
    "        cls: Type[\"MatchingEngine\"],\n",
    "        project_id: str,\n",
    "        region: str,\n",
    "        gcs_bucket_name: str,\n",
    "        index_id: str,\n",
    "        endpoint_id: str,\n",
    "        credentials_path: Optional[str] = None,\n",
    "        embedding: Optional[Embeddings] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"MatchingEngine\":\n",
    "        \"\"\"Takes the object creation out of the constructor.\n",
    "\n",
    "        Args:\n",
    "            project_id: The GCP project id.\n",
    "            region: The default location making the API calls. It must have\n",
    "            the same location as the GCS bucket and must be regional.\n",
    "            gcs_bucket_name: The location where the vectors will be stored in\n",
    "            order for the index to be created.\n",
    "            index_id: The id of the created index.\n",
    "            endpoint_id: The id of the created endpoint.\n",
    "            credentials_path: (Optional) The path of the Google credentials on\n",
    "            the local file system.\n",
    "            embedding: The :class:`Embeddings` that will be used for\n",
    "            embedding the texts.\n",
    "            kwargs: Additional keyword arguments to pass to MatchingEngine.__init__().\n",
    "\n",
    "        Returns:\n",
    "            A configured MatchingEngine with the texts added to the index.\n",
    "        \"\"\"\n",
    "        gcs_bucket_name = cls._validate_gcs_bucket(gcs_bucket_name)\n",
    "        credentials = cls._create_credentials_from_file(credentials_path)\n",
    "        index = cls._create_index_by_id(index_id, project_id, region, credentials)\n",
    "        endpoint = cls._create_endpoint_by_id(\n",
    "            endpoint_id, project_id, region, credentials\n",
    "        )\n",
    "\n",
    "        gcs_client = cls._get_gcs_client(credentials, project_id)\n",
    "        cls._init_aiplatform(project_id, region, gcs_bucket_name, credentials)\n",
    "\n",
    "        return cls(\n",
    "            project_id=project_id,\n",
    "            index=index,\n",
    "            endpoint=endpoint,\n",
    "            embedding=embedding or cls._get_default_embeddings(),\n",
    "            gcs_client=gcs_client,\n",
    "            credentials=credentials,\n",
    "            gcs_bucket_name=gcs_bucket_name,\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def _validate_gcs_bucket(cls, gcs_bucket_name: str) -> str:\n",
    "        \"\"\"Validates the gcs_bucket_name as a bucket name.\n",
    "\n",
    "        Args:\n",
    "              gcs_bucket_name: The received bucket uri.\n",
    "\n",
    "        Returns:\n",
    "              A valid gcs_bucket_name or throws ValueError if full path is\n",
    "              provided.\n",
    "        \"\"\"\n",
    "        gcs_bucket_name = gcs_bucket_name.replace(\"gs://\", \"\")\n",
    "        if \"/\" in gcs_bucket_name:\n",
    "            raise ValueError(\n",
    "                f\"The argument gcs_bucket_name should only be \"\n",
    "                f\"the bucket name. Received {gcs_bucket_name}\"\n",
    "            )\n",
    "        return gcs_bucket_name\n",
    "\n",
    "    @classmethod\n",
    "    def _create_credentials_from_file(\n",
    "        cls, json_credentials_path: Optional[str]\n",
    "    ) -> Optional[Credentials]:\n",
    "        \"\"\"Creates credentials for GCP.\n",
    "\n",
    "        Args:\n",
    "             json_credentials_path: The path on the file system where the\n",
    "             credentials are stored.\n",
    "\n",
    "         Returns:\n",
    "             An optional of Credentials or None, in which case the default\n",
    "             will be used.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.oauth2 import service_account\n",
    "\n",
    "        credentials = None\n",
    "        if json_credentials_path is not None:\n",
    "            credentials = service_account.Credentials.from_service_account_file(\n",
    "                json_credentials_path\n",
    "            )\n",
    "\n",
    "        return credentials\n",
    "\n",
    "    @classmethod\n",
    "    def _create_index_by_id(\n",
    "        cls, index_id: str, project_id: str, region: str, credentials: \"Credentials\"\n",
    "    ) -> MatchingEngineIndex:\n",
    "        \"\"\"Creates a MatchingEngineIndex object by id.\n",
    "\n",
    "        Args:\n",
    "            index_id: The created index id.\n",
    "            project_id: The project to retrieve index from.\n",
    "            region: Location to retrieve index from.\n",
    "            credentials: GCS credentials.\n",
    "\n",
    "        Returns:\n",
    "            A configured MatchingEngineIndex.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform\n",
    "\n",
    "        logger.debug(f\"Creating matching engine index with id {index_id}.\")\n",
    "        return aiplatform.MatchingEngineIndex(\n",
    "            index_name=index_id,\n",
    "            project=project_id,\n",
    "            location=region,\n",
    "            credentials=credentials,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _create_endpoint_by_id(\n",
    "        cls, endpoint_id: str, project_id: str, region: str, credentials: \"Credentials\"\n",
    "    ) -> MatchingEngineIndexEndpoint:\n",
    "        \"\"\"Creates a MatchingEngineIndexEndpoint object by id.\n",
    "\n",
    "        Args:\n",
    "            endpoint_id: The created endpoint id.\n",
    "            project_id: The project to retrieve index from.\n",
    "            region: Location to retrieve index from.\n",
    "            credentials: GCS credentials.\n",
    "\n",
    "        Returns:\n",
    "            A configured MatchingEngineIndexEndpoint.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform\n",
    "\n",
    "        logger.debug(f\"Creating endpoint with id {endpoint_id}.\")\n",
    "        return aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name=endpoint_id,\n",
    "            project=project_id,\n",
    "            location=region,\n",
    "            credentials=credentials,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _get_gcs_client(\n",
    "        cls, credentials: \"Credentials\", project_id: str\n",
    "    ) -> \"storage.Client\":\n",
    "        \"\"\"Lazily creates a GCS client.\n",
    "\n",
    "        Returns:\n",
    "            A configured GCS client.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import storage\n",
    "\n",
    "        return storage.Client(\n",
    "            credentials=credentials,\n",
    "            project=project_id,\n",
    "            client_info=get_client_info(module=\"vertex-ai-matching-engine\"),\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _init_aiplatform(\n",
    "        cls,\n",
    "        project_id: str,\n",
    "        region: str,\n",
    "        gcs_bucket_name: str,\n",
    "        credentials: \"Credentials\",\n",
    "    ) -> None:\n",
    "        \"\"\"Configures the aiplatform library.\n",
    "\n",
    "        Args:\n",
    "            project_id: The GCP project id.\n",
    "            region: The default location making the API calls. It must have\n",
    "            the same location as the GCS bucket and must be regional.\n",
    "            gcs_bucket_name: GCS staging location.\n",
    "            credentials: The GCS Credentials object.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform\n",
    "\n",
    "        logger.debug(\n",
    "            f\"Initializing AI Platform for project {project_id} on \"\n",
    "            f\"{region} and for {gcs_bucket_name}.\"\n",
    "        )\n",
    "        aiplatform.init(\n",
    "            project=project_id,\n",
    "            location=region,\n",
    "            staging_bucket=gcs_bucket_name,\n",
    "            credentials=credentials,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _get_default_embeddings(cls) -> \"TensorflowHubEmbeddings\":\n",
    "        \"\"\"This function returns the default embedding.\n",
    "\n",
    "        Returns:\n",
    "            Default TensorflowHubEmbeddings to use.\n",
    "        \"\"\"\n",
    "\n",
    "        from langchain_community.embeddings import TensorflowHubEmbeddings\n",
    "\n",
    "        return TensorflowHubEmbeddings()\n",
    "    \n",
    "\n",
    "class CustomVertexAIEmbeddings_v2(VertexAIEmbeddings, BaseModel):\n",
    "\n",
    "    # Overriding embed_query method\n",
    "    def embed_query(self, text: str):\n",
    "        embeddings = self.client.get_embeddings([text])[0].values\n",
    "        adapted_query_embeddings = np.matmul(best_matrix, np.array(embeddings).T).tolist()\n",
    "        \n",
    "        return adapted_query_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a829a0c-a0f7-4d24-8de9-0dc521f44d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings API integrated with langChain\n",
    "\n",
    "PROJECT_ID=\"engaged-domain-403109\"\n",
    "REGION=\"asia-southeast1\"\n",
    "GCS_BUCKET=\"engaged-domain-403109-me-bucket\"\n",
    "ME_INDEX_ID=\"projects/510519063638/locations/asia-southeast1/indexes/4693366538231611392\"\n",
    "ME_ENDPOINT_ID=\"projects/510519063638/locations/asia-southeast1/indexEndpoints/3617586769429528576\"\n",
    "\n",
    "QUERY_EXAMPLES_FILENAME = 'data/embedding_adapter_training/query_examples.csv'\n",
    "\n",
    "ME_REGION = REGION\n",
    "ME_INDEX_NAME = f\"{PROJECT_ID}-me-index\"  # @param {type:\"string\"}\n",
    "ME_EMBEDDING_DIR = f\"{PROJECT_ID}-me-bucket\"  # @param {type:\"string\"}\n",
    "ME_DIMENSIONS = 768  # when using Vertex PaLM Embedding\n",
    "REGION=\"asia-southeast1\"\n",
    "\n",
    "# Utility functions for Embeddings API with rate limiting\n",
    "def rate_limit(max_per_minute):\n",
    "    period = 60 / max_per_minute\n",
    "    print(\"Waiting\")\n",
    "    while True:\n",
    "        before = time.time()\n",
    "        yield\n",
    "        after = time.time()\n",
    "        elapsed = after - before\n",
    "        sleep_time = max(0, period - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            print(\".\", end=\"\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "class CustomVertexAIEmbeddings(VertexAIEmbeddings, BaseModel):\n",
    "    requests_per_minute: int\n",
    "    num_instances_per_batch: int\n",
    "\n",
    "    # Overriding embed_documents method\n",
    "    def embed_documents(self, texts: List[str]):\n",
    "        limiter = rate_limit(self.requests_per_minute)\n",
    "        results = []\n",
    "        docs = list(texts)\n",
    "\n",
    "        while docs:\n",
    "            # Working in batches because the API accepts maximum 5\n",
    "            # documents per request to get embeddings\n",
    "            head, docs = (\n",
    "                docs[: self.num_instances_per_batch],\n",
    "                docs[self.num_instances_per_batch :],\n",
    "            )\n",
    "            chunk = self.client.get_embeddings(head)\n",
    "            results.extend(chunk)\n",
    "            next(limiter)\n",
    "\n",
    "        return [r.values for r in results]\n",
    "    \n",
    "# Embeddings API integrated with langChain\n",
    "EMBEDDING_QPM = 100\n",
    "EMBEDDING_NUM_BATCH = 5\n",
    "embeddings = CustomVertexAIEmbeddings(\n",
    "    requests_per_minute=EMBEDDING_QPM,\n",
    "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
    ")\n",
    "\n",
    "\n",
    "embeddings_v2 = CustomVertexAIEmbeddings_v2()\n",
    "embeddings_v2.location = REGION\n",
    "\n",
    "# Show embeddings_v2 config\n",
    "embeddings_v2\n",
    "# Load matching engine\n",
    "me_v2 = CustomMatchingEngine.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    gcs_bucket_name=GCS_BUCKET,\n",
    "    embedding=embeddings,\n",
    "    adapted_embedding=embeddings_v2,\n",
    "    index_id=ME_INDEX_ID,\n",
    "    endpoint_id=ME_ENDPOINT_ID,\n",
    ")\n",
    "\n",
    "# Get retriever from matching engine\n",
    "NUMBER_OF_RESULTS = 4\n",
    "retriever_v2 = me_v2.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": NUMBER_OF_RESULTS,\n",
    "        },\n",
    "    )\n",
    "\n",
    "model = ChatVertexAI(model_name=\"chat-bison-32k\",temperature=0, verbose=True, max_tokens=32768)\n",
    "\n",
    "# create QA retriever\n",
    "# qa_v2 = RetrievalQA.from_chain_type(\n",
    "#     llm=model,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=retriever_v2,\n",
    "#     return_source_documents=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffbe1c-6a94-4996-8fe3-089709da3195",
   "metadata": {},
   "source": [
    "# Embedding Layer + Doc Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62a86b82-85ea-4916-b183-b5139dba3722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='You can also check out this list of inclusive leisure/ recreation groups that specialise in activities such as horticulture, arts and crafts, music and sports as well as these events here.\\n\\nGeneral information\\n\\nActions to take\\n\\nVisit the Enabling Village, which is equipped with accessibility features and various amenities for those with disabilities.\\n\\nWhen deciding what to do for the weekend, it helps to plan ahead by \\x00nding out if a place is wheelchair-accessible or has other features to accommodate persons with disabilities as not all buildings are accessible.'\n",
      "\n",
      "page_content='Hearing\\n\\nPhysical Disability\\n\\nTech Able is located at the Enabling Village and showcases a wide range of AT devices, highlighting the possibilities of AT for work, learning and living. The centre jointly managed by SG Enable and SPD and provides consultation, assessment and training for persons with disabilities.\\n\\nThe Tech Able web app provides more information about AT devices that may suit persons with disabilities and their caregivers. When in Tech Able, users can select one of the four virtual guides for a guided tour, and they will highlight some of the AT devices that can help lower barriers for persons with disabilities for work, learn, play and living. Users who are interested to purchase or \\x00nd out more about an AT device may contact the vendors directly. Vendors details are listed within.\\n\\nObtaining an assistive technology device\\n\\nActions to take\\n\\nRequest for an AT assessment through your regular therapist or social worker.'\n",
      "\n",
      "page_content='ABOUT THE WRITER\\n\\n(/auth\\n\\nTan Jia Hui (/author/jiahuitan/)\\n\\nJia Hui is a content marketer who loves helping others and hopes to make this world a kinder place in any way she can. In her pockets of free time, you can nd her snacking on ice cream and fries with her 80-year-young Grandma at home.\\n\\nRELATED ARTICLES\\n\\nCOSTS & FINANCING\\n\\nCOSTS & FINANCING\\n\\nUnderstanding severe disability and why it pays to plan ahead\\n\\nStep-by-Step Guide On How To Switch From ElderShield To CareShield Life\\n\\n(/resources/understanding-severe-disability-and-why-it-pays-to-plan- ahead/)\\n\\n(/resources/eldershield-careshield-life-switch/)\\n\\nCall us (tel:6100 0055)\\n\\n\\ue91a\\n\\n(https://www.homage.sg)\\n\\nCOSTS & FINANCING\\n\\nCOSTS & FINANCING\\n\\nPlanning for Your Parents Retirement in Singapore: What You Need to Know\\n\\n[2023] Cancer Drug List (CDL) and changes to cancer insurance, claims, and subsidies\\n\\n(/resources/retirement-planning-for-parents/)\\n\\n(/resources/cancer-treatment-updates/)\\n\\nMake Home Care Personal To Your Loved One'\n",
      "\n",
      "page_content='Trains and train stations also have various accessibility features. These include tactile indicators on the \\x00oor for people with visual impairment, wider fare gates for wheelchair users, and information at station platforms on arrival times and destinations of the approaching trains.\\n\\nThere is an app to help you decide on an alternative travel routes to reach your destination. MyTransport.SG o\\x00ers travel information and features to help commuters get around, and includes a new feature to inform commuters about planned lift service maintenance at MRT and LRT stations. For step-by-step instructions to access the lift maintenance feature, click here.\\n\\nConcession cards\\n\\nChildren up to 0.9m in height and who are accompanied by a fare-paying commuter can travel for free. For other commuters, a range of concession cards are available to reduce the cost of public transport.\\n\\nPublic transport concession for persons with disabilities'\n"
     ]
    }
   ],
   "source": [
    "docs = retriever_v2.get_relevant_documents('Tell me what are the available support I can get. My grandmother fell and is in need of financial assistance.')\n",
    "print(*docs, sep='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bc171-dd7a-4395-83ab-be7df28caf5c",
   "metadata": {},
   "source": [
    "# Current Implementation of Doc Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ef5315-5b2d-4a6f-8841-59998f58f76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise embedding object\n",
    "embeddings = VertexAIEmbeddings(location=REGION, model_name=\"textembedding-gecko@001\")\n",
    "\n",
    "# Load matching engine\n",
    "me = MatchingEngine.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    gcs_bucket_name=GCS_BUCKET,\n",
    "    embedding=embeddings,\n",
    "    index_id=ME_INDEX_ID,\n",
    "    endpoint_id=ME_ENDPOINT_ID,\n",
    ")\n",
    "\n",
    "NUMBER_OF_RESULTS = 4\n",
    "retriever = me.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": NUMBER_OF_RESULTS,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c659766-83e0-4b78-a1f0-1e7b32d816ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"(https://www.aic.sg)\\n\\n\\uf002\\n\\nContact Us (https://www.aic.sg/about-us/contact-us-form/)\\n\\ne-Care Locator (https://supportgowhere.life.gov.sg/caregiving)\\n\\ne-FASS (https://e\\x00nance.aic.sg/)\\n\\nFinancial Assistance\\n\\nCare Services\\n\\nCaregiving\\n\\nCommunity\\n\\nHome (https://www.aic.sg/) \\uf0da Financial Assistance\\n\\nFinancial Assistance\\n\\nCare Subsidies And Funds\\n\\nGet the support you and your loved one need.\\n\\nEveryday Needs\\n\\nFinancial support is available as your care needs change. From daily costs of living to medical fees assistance, theres an array of support on hand.\\n\\nExpand All\\n\\n\\uf068\\n\\nSeniors' Mobility and Enabling Fund (SMF)\\n\\nSubsidises care items ranging from wheelchairs and hearing aids\\n\\nto milk supplements.\\n\\nLearn More (https://www.aic.sg/\\x00nancial- assistance/seniors-mobility-and-enabling-fund-smf/)\\n\\n\\uf067\\n\\nEnhancement for Active Seniors (EASE)\\n\\nPioneer Generation Disability Assistance Scheme (PioneerDAS)\\n\\n\\uf067\\n\\n\\uf067\\n\\nCareShield Life\\n\\n\\uf067\\n\\nElderShield\\n\\nInterim Disability Assistance Programme for the Elderly (IDAPE)\"\n",
      "\n",
      "page_content='Click here (https://www.enablingguide.sg/im-looking-for-disability-support/assistive-technology/assistive-technology-fund) for more information on ATF.\\n\\nComCare Short-To-Medium-Term Assistance (SMTA)\\n\\nCall us (tel:6100 0055)\\n\\n\\ue91a\\n\\n(https://www.homage.sg)\\n\\nFor those who are temporarily unable to work due to an injury or illness, are looking for a job, or require income supplement, short-term nancial support is available\\n\\nwith ComCare Short-To-Medium-Term Assistance.\\n\\nBenets\\n\\nMonthly cash assistance for living expenses\\n\\nAssistance with your household bills, including rental, utilities, and/or service and conservancy charges\\n\\nAssistance with medical bills at polyclinics and government or restructured hospitals\\n\\nEmployment assistance such as job search and/or training, by a Career Coach from Workforce Singapore (WSG) and NTUC e2i\\n\\nReferrals to other government agencies and community partners, such as Family Service Centres (FSCs) (https://www.homage.sg/resources/family-service-centre-'\n",
      "\n",
      "page_content='mentioned that they need nancial assistance or proper training to care for an elderly family member, but are unaware of the schemes available.\\n\\nWith this handy guide on eldercare grants and subsidies in Singapore, we hope that you will be able to effectively make use of the support available to help you\\n\\ndefray the high costs associated with caregiving and decide on the scheme that best suits your needs.\\n\\nHome Caregiving Grant (HCG)\\n\\nCall us (tel:6100 0055)\\n\\n\\ue91a\\n\\n(https://www.homage.sg)\\n\\nCaregivers have shared that the cost of caregiving is amongst the uppermost issues in their minds. From October 2019, the Home Caregiving Grant (HCG)\\n\\n(https://www.homage.sg/resources/home-caregiving-grant/) will replace the Foreign Domestic Worker (FDW) Grant (https://www.aic.sg/nancial-assistance/home-\\n\\ncaregiving-grant) as part of the new Caregiver Support Action Plan to lighten the nancial load of caregiving.'\n",
      "\n",
      "page_content='available to you, to better support you in your journey.\\n\\nDo take note that some of these schemes may require you to undergo a means-testing assessment (https://www.homage.sg/resources/means-testing/) to determine\\n\\nyour eligibility for the subsidy, and the amount of subsidy you receive.\\n\\nShould you or someone you know need support caring for a senior loved one (https://www.homage.sg/services/elderly-care/), we are here to help. Homage provides\\n\\ncaregiving services for your loved ones at every stage. Our trained care professionals are able to provide companionship, nursing care, night caregiving, home therapy\\n\\nand more (https://www.homage.sg/services/), to keep your loved ones active and engaged.\\n\\nProvide the best care to your loved one today! Fill up the form below for a free consultation with our Care Advisory team.\\n\\nFill out the form below and our Care Advisors will get back to you with care information you need.'\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents('Tell me what are the available support I can get. My grandmother fell and is in need of financial assistance.')\n",
    "print(*docs, sep='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
